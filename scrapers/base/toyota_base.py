# import re
# import requests
# import pandas as pd
# from scrapers.base.base_scraper import BaseScraper


# URL = "https://www.hollywoodtoyota.com/api/widget/ws-specials/promos"

# HEADERS = {
#     "Content-Type": "application/json",
#     "Accept": "application/json",
#     "User-Agent": "Mozilla/5.0",
# }

# PAYLOAD = {
#     "parameters": {
#         "eo": {
#             "pixallId": "xBzPvgXhZ2oHtSojH6BON5Ol",
#             "enablePersonalization": "true",
#         },
#         "filterRO": {
#             "limitByInventory": "true",
#             "excludeModelOffersWithoutPhotos": "false",
#             "limitByTags": [],
#             "limitByTagsType": "INCLUDE",
#             "listingConfigId": "auto-new",
#             "specialCount": "30",
#             "vehicleId": "",
#         },
#         "promoRO": {
#             "accountId": "toyotaofhollywood6000hollywoodblvd",
#             "autoGeneratedSpecialLimit": "0",
#             "deviceType": "DESKTOP",
#             "locale": "en_US",
#             "placements": "listing",
#             "types": ["vehicle", "incentive"],
#         },
#         "removeVcdaRequest": "true",
#         "requireAccountInfo": "true",
#     }
# }


# def extract(pattern: str, text: str):
#     m = re.search(pattern, text or "", re.IGNORECASE)
#     return m.group(1) if m else None


# def to_int(val):
#     if val is None:
#         return None
#     return int(val.replace(",", ""))


# class ToyotaBaseScraper(BaseScraper):
#     dealer_name = "Toyota of Hollywood"
#     specials_url = "https://www.hollywoodtoyota.com/newspecials.htm"

#     def fetch_df(self) -> pd.DataFrame:
#         resp = requests.post(URL, json=PAYLOAD, headers=HEADERS, timeout=15)
#         resp.raise_for_status()
#         data = resp.json()

#         rows = []

#         for promo in data.get("promos", []):
#             disclaimer = promo.get("disclaimer", "") or ""

#             rows.append({
#                 "Model": promo.get("title"),
#                 "Monthly ($)": to_int(extract(r"\$(\d+)\s*per\s*month", disclaimer)),
#                 "Term (months)": to_int(extract(r"for\s*(\d+)\s*months", disclaimer)),
#                 "Due at Signing ($)": to_int(extract(r"\$([\d,]+)\s*Due\s*At\s*Signing", disclaimer)),
#                 "MSRP ($)": to_int(extract(r"TSRP\s*\$([\d,]+)", disclaimer)),
#                 "APR (%)": None,
#                 "Expires": promo.get("endDateDisplay"),
#                 "Dealer Specials Link": self.specials_url,
#             })

#         return pd.DataFrame(rows)


import re
from scrapers.base.base_scraper import BaseScraper


class ToyotaBaseScraper(BaseScraper):
    """
    ABSTRACT Toyota base.
    NO network calls.
    NO dealer-specific logic.
    """

    @staticmethod
    def extract(pattern: str, text: str | None):
        if not text:
            return None
        m = re.search(pattern, text, re.IGNORECASE)
        return m.group(1) if m else None

    @staticmethod
    def money_to_int(text: str | None):
        if not text:
            return None
        digits = re.sub(r"[^\d]", "", text)
        return int(digits) if digits else None

    @staticmethod
    def first_int(text: str | None):
        if not text:
            return None
        m = re.search(r"(\d+)", text)
        return int(m.group(1)) if m else None

